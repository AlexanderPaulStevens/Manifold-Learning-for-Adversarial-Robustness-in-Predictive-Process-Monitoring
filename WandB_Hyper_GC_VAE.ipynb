{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1400,"status":"ok","timestamp":1686590138327,"user":{"displayName":"Alexander Stevens","userId":"06895933540823444481"},"user_tz":-120},"id":"9FU_59Cc9wyx","outputId":"b2e20b11-c63c-46fc-a1cb-0dae6286756a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/CurrentWork/Manifold/AdversarialRobustnessGeneralization\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/CurrentWork/Manifold/AdversarialRobustnessGeneralization"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13814,"status":"ok","timestamp":1686590152138,"user":{"displayName":"Alexander Stevens","userId":"06895933540823444481"},"user_tz":-120},"id":"RdtQRWXV-pSo","outputId":"f7e64760-c708-4ada-b9e5-a5a6058e878b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: wandb==0.13.4 in /usr/local/lib/python3.10/dist-packages (0.13.4)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.4) (8.1.3)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.4) (3.1.31)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.4) (2.27.1)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.4) (2.3)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.4) (1.0.11)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.4) (5.9.5)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.4) (1.25.1)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.4) (1.16.0)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.4) (0.4.0)\n","Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.4) (3.20.3)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.4) (6.0)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.4) (0.1.2)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.4) (1.3.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb==0.13.4) (67.7.2)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython>=1.0.0->wandb==0.13.4) (4.0.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.13.4) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.13.4) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.13.4) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.13.4) (3.4)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb==0.13.4) (5.0.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.10/dist-packages (7.352.0)\n"]}],"source":["!pip install wandb==0.13.4\n","!pip install nvidia-ml-py3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":815},"id":"dcEld2vBOikP","executionInfo":{"status":"ok","timestamp":1686590183762,"user_tz":-120,"elapsed":31640,"user":{"displayName":"Alexander Stevens","userId":"06895933540823444481"}},"outputId":"bf9acd4a-e66e-4332-a3d2-b09f11f46239"},"outputs":[{"output_type":"stream","name":"stdout","text":["path manifolds/wandb/bpic2012_cancelled_deviant\n","Dataset: bpic2012_cancelled\n","label: deviant\n","prefix length 15 20\n","AMOUNT_REQ                 305\n","Case ID                   4685\n","label                        2\n","Activity                    36\n","Resource                    63\n","lifecycle:transition         3\n","timesincemidnight         1151\n","timesincelastevent      110819\n","timesincecasestart      163829\n","event_nr                   175\n","month                        6\n","weekday                      7\n","hour                        24\n","open_cases                 880\n","Complete Timestamp      173152\n","dtype: int64\n"]},{"output_type":"stream","name":"stderr","text":["INFO:wandb.agents.pyagent:Starting sweep agent: entity=adversarial_robustness, project=Bayes_VAE, count=15\n"]},{"output_type":"stream","name":"stdout","text":["Create sweep with ID: 81h1dxj9\n","Sweep URL: https://wandb.ai/adversarial_robustness/Bayes_VAE/sweeps/81h1dxj9\n","tensor([[10,  7,  8,  ..., -1, -1, -1],\n","        [10,  7,  8,  ..., -1, -1, -1],\n","        [10,  7,  8,  ..., -1, -1, -1],\n","        ...,\n","        [10,  7,  8,  ..., -1, -1, -1],\n","        [10,  7,  8,  ..., -1, -1, -1],\n","        [10,  7,  8,  ..., 24, -1, -1]], device='cuda:0')\n","LSTM_VAE(\n","  (embed_act): Embedding(37, 32)\n","  (embed_res): Embedding(58, 32)\n","  (encoder_lstm): LSTM(64, 16, batch_first=True)\n","  (mean): Linear(in_features=16, out_features=16, bias=True)\n","  (log_variance): Linear(in_features=16, out_features=16, bias=True)\n","  (init_hidden_decoder): Linear(in_features=16, out_features=16, bias=True)\n","  (decoder_lstm): LSTM(64, 16, batch_first=True)\n","  (output_act): Linear(in_features=16, out_features=37, bias=True)\n","  (output_res): Linear(in_features=16, out_features=58, bias=True)\n","  (log_softmax_act): LogSoftmax(dim=2)\n","  (log_softmax_res): LogSoftmax(dim=2)\n",")\n","Epoch:  0\n","Training.......\n"]},{"output_type":"stream","name":"stderr","text":["Run f1lnd4dm errored: RuntimeError('CUDA error: device-side assert triggered\\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\\n')\n"]}],"source":["import sys\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n","import wandb\n","import pandas as pd\n","sys.path.append(os.getcwd())\n","import pickle\n","import numpy as np\n","import pandas as pd\n","# packages from https://github.com/irhete/predictive-monitoring-benchmark/blob/master/experiments/experiments.py\n","from DatasetManager import DatasetManager\n","#packages from https://github.com/Khamies/LSTM-Variational-AutoEncoder/tree/50476dd3bfe146bf8f4a74a205b78fb142e99423\n","from train import Trainer\n","from settings import global_setting, model_setting, training_setting\n","from loss import VAE_Loss\n","from VAE import LSTM_VAE, CheckpointSaver\n","#user-specified packages\n","from util.DataCreation import DataCreation\n","from util.Arguments import Args\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","import torch\n","# Use GPU if available\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","# to explicitly raise an error with a stack trace to easier debug which operation might have created the invalid values\n","torch.autograd.set_detect_anomaly(True)\n","#hyperopt\n","import hyperopt\n","from hyperopt import hp, Trials, fmin, tpe, STATUS_OK\n","from hyperopt.pyll.base import scope\n","import yaml\n","# set logging\n","import logging\n","logging.getLogger().setLevel(logging.INFO)\n","##################################################################\n","\n","dataset_ref_to_datasets = {\n","    \"production\": [\"production\"],\n","    \"bpic2015\": [\"bpic2015_%s_f2\"%(municipality) for municipality in range(1,6)],\n","    \"bpic2012\": [\"bpic2012_accepted\",\"bpic2012_cancelled\",\"bpic2012_declined\"],\n","    \"hospital_billing\": [\"hospital_billing_%s\"%suffix for suffix in [2,3]],\n","    \"traffic_fines\": [\"traffic_fines_%s\" % formula for formula in range(1, 2)],\n","    # \"bpic2017\": [\"bpic2017_accepted\",\"bpic2017_cancelled\",\"bpic2017_refused\"],\n","    #\"sepsis_cases\": [\"sepsis_cases_2\",\"sepsis_cases_4\"],\n","    #\"bpic2011\": [\"bpic2011_f%s\"%formula for formula in range(2,4)],\n","    }\n","\n","labels = ['regular','deviant']\n","\n","dataset_name= 'bpic2012_cancelled'\n","label= 'deviant'\n","\n","path = 'manifolds/wandb/'+dataset_name+'_'+label\n","print('path',path)\n","os.environ['WANDB_DIR']= path\n","os.environ[\"WANDB_SILENT\"] = \"true\"\n","\n","seed = global_setting['seed']\n","epochs = training_setting['epochs']\n","n_splits = global_setting['n_splits']\n","max_evals = global_setting['max_evals']\n","train_ratio = global_setting['train_ratio']\n","clip = training_setting[\"clip\"]\n","embed_size = training_setting[\"embed_size\"]\n","\n","project_name = 'Bayes_VAE'\n","dataset_group = 'VAE'\n","name = dataset_group + '_' + dataset_name + '_' + label\n","\n","print('Dataset:', dataset_name)\n","print('label:', label)\n","dataset_manager = DatasetManager(dataset_name)\n","data = dataset_manager.read_dataset()\n","arguments = Args(dataset_name)\n","cls_encoder_args, min_prefix_length, max_prefix_length, activity_col, resource_col = arguments.extract_args(data, dataset_manager)\n","print('prefix length',min_prefix_length,max_prefix_length)\n","print(data.nunique())\n","\n","cat_cols = [activity_col, resource_col]\n","cols = ['Case ID', 'label', 'case_length'] + cat_cols\n","datacreator = DataCreation(dataset_manager,dataset_name)\n","no_cols_list = []\n","# split into training and test\n","train, _ = dataset_manager.split_data_strict(data, train_ratio, split=\"temporal\")\n","for i in cat_cols:\n","    _, _, _, no_cols = datacreator.create_indexes(i, train)\n","    no_cols_list.append(no_cols)\n","\n","vocab_size = [no_cols_list[0]+1,no_cols_list[1]+1]\n","# cat columns integerencoded\n","\n","#you don't need to do that for the test data, as the prepare inputs is only fitted on the training data\n","# prepare chunks for CV\n","dt_prefixes = []\n","for train_chunk, test_chunk in dataset_manager.get_stratified_split_generator(train, n_splits=n_splits):\n","    # generate data where each prefix is a separate instance\n","    dt_prefixes.append(dataset_manager.generate_prefix_data(test_chunk, min_prefix_length, max_prefix_length))\n","del train\n","\n","\n","#######WANDB################\n","with open(\"config/VAE_sweep.yaml\", 'r') as stream:\n","    sweep_config = yaml.safe_load(stream)\n","\n","sweep_config['name'] =  name\n","sweep_id = wandb.sweep(sweep_config, project=project_name, entity=\"adversarial_robustness\")\n","\n","iterations= max_evals\n","\n","def train(config=None):\n","\t# Initialize a new wandb run\n","    with wandb.init(config=config,project=project_name, group=name, save_code=False) as run:\n","        # If called by wandb.agent, as below,\n","        # this config will be set by Sweep Controller\n","        config = wandb.config\n","        batch_size = config[\"batch_size\"]\n","        latent_size = config[\"latent_size\"]\n","        hidden_size = latent_size\n","        learning_rate = config['learning_rate']\n","        for cv_iter in range(n_splits):\n","            dt_test_prefixes = dt_prefixes[cv_iter]\n","            dt_train_prefixes = pd.DataFrame()\n","            for cv_train_iter in range(n_splits):\n","                if cv_train_iter != cv_iter:\n","                    dt_train_prefixes = pd.concat([dt_train_prefixes, dt_prefixes[cv_train_iter]], axis=0)\n","\n","        #######################METHODOLOGY#################################\n","        dt_train_prefixes = dt_train_prefixes[cols].copy()\n","        dt_test_prefixes = dt_test_prefixes[cols].copy()\n","        # cat columns integerencoded\n","        train_cat_cols, test_cat_cols, _ = datacreator.prepare_inputs(dt_train_prefixes.loc[:,cat_cols], dt_test_prefixes.loc[:,cat_cols])\n","        dt_test_prefixes[cat_cols] = test_cat_cols\n","        dt_train_prefixes[cat_cols] = train_cat_cols\n","        del train_cat_cols, test_cat_cols\n","\n","        dt_train_prefixes = dt_train_prefixes[dt_train_prefixes['label']==label]\n","        dt_test_prefixes = dt_test_prefixes[dt_test_prefixes['label']==label]\n","\n","        # groupby case ID\n","        ans_train_act = datacreator.groupby_caseID(dt_train_prefixes, cols, activity_col)\n","        ans_test_act = datacreator.groupby_caseID(dt_test_prefixes, cols, activity_col)\n","        ans_train_res = datacreator.groupby_caseID(dt_train_prefixes, cols, resource_col)\n","        ans_test_res = datacreator.groupby_caseID(dt_test_prefixes, cols, resource_col)\n","        del dt_train_prefixes, dt_test_prefixes\n","\n","        ######ACTIVITY_COL########\n","        activity_train = datacreator.pad_data(ans_train_act).to(device)\n","        activity_test = datacreator.pad_data(ans_test_act).to(device)\n","        print(activity_test)\n","        del ans_train_act, ans_test_act\n","        # ######RESOURCE COL########\n","        resource_train = datacreator.pad_data(ans_train_res).to(device)\n","        resource_test = datacreator.pad_data(ans_test_res).to(device)\n","        del ans_train_res, ans_test_res\n","\n","        ###################MODEL ARCHITECTURE#################################################\n","        # create the input layers and embeddings\n","        input_size = no_cols_list\n","        dataset = torch.utils.data.TensorDataset(activity_train, resource_train)\n","        dataset = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n","        del activity_train, resource_train\n","        dataset_test = torch.utils.data.TensorDataset(activity_test, resource_test)\n","        dataset_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True, drop_last=True)\n","        del activity_test, resource_test\n","        model = LSTM_VAE(vocab_size=vocab_size, embed_size=embed_size, hidden_size=latent_size, latent_size=latent_size).to(device)\n","        print(model)\n","        if config['optimizer']=='RMSprop':\n","            optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n","        elif config['optimizer']=='Nadam':\n","            optimizer = torch.optim.NAdam(model.parameters(), lr=learning_rate)\n","\n","        Loss = VAE_Loss()\n","        trainer = Trainer(dataset, dataset_test, model, Loss, optimizer)\n","        # Epochs\n","        train_losses = []\n","        test_losses = []\n","        total_elbo = []\n","        total_KL = []\n","        total_recon = []\n","         # checkpoint saver\n","        path = 'manifolds/'+dataset_name+'_'+label\n","        checkpoint_saver = CheckpointSaver(dirpath=path, decreasing=True, top_n=1)\n","        for epoch in range(epochs):\n","            print(\"Epoch: \", epoch)\n","            print(\"Training.......\")\n","            train_losses = trainer.train(train_losses, epoch, batch_size, clip)\n","            print('testing........')\n","            test_losses =  trainer.test(test_losses, epoch, batch_size)\n","            elbo_loss = list(map(lambda x: x[0], test_losses))\n","            elbo_loss = np.mean([tensor for tensor in elbo_loss])\n","            print('loss',elbo_loss)\n","            checkpoint_saver(model, epoch, elbo_loss, learning_rate, latent_size, config['optimizer'], batch_size)\n","            wandb.log({\"validation_loss\": elbo_loss})\n","        # Get the lowest validation loss of the training epochs\n","wandb.agent(sweep_id, function= train, count=iterations, project=project_name, entity=\"adversarial_robustness\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LkWt2p9x_p-3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686590183763,"user_tz":-120,"elapsed":7,"user":{"displayName":"Alexander Stevens","userId":"06895933540823444481"}},"outputId":"6942115b-7ff1-45e2-dca4-2fa5b7855870"},"outputs":[{"output_type":"stream","name":"stdout","text":["hello\n"]}],"source":["print('hello')"]},{"cell_type":"code","source":[],"metadata":{"id":"KzZ-hwfCjSSC"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMzjoe2qWAq1213Vn+PMsh1"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}